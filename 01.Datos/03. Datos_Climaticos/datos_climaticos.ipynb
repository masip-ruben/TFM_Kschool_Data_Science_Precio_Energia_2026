{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31888da7",
   "metadata": {},
   "source": [
    "### Inicialización de librerías y marca temporal de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8bd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode\n",
    "fecha = datetime.now().strftime('%Y%m%d_%H%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218dbd6",
   "metadata": {},
   "source": [
    "### Carga y visualización inicial del fichero de mallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b971b624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "poblacion_total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e4d8e2fd-9928-43ec-b691-050d61a875f8",
       "rows": [
        [
         "0",
         "14458",
         "43.01008776",
         "-9.188413044333332"
        ],
        [
         "1",
         "260901",
         "37.257363038571434",
         "-7.200928419999999"
        ],
        [
         "2",
         "217987",
         "37.965370157307696",
         "-7.138822035"
        ],
        [
         "3",
         "20120",
         "39.49920750818182",
         "-7.171370430363637"
        ],
        [
         "4",
         "169450",
         "42.033670423414634",
         "-7.933325822585366"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poblacion_total</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14458</td>\n",
       "      <td>43.010088</td>\n",
       "      <td>-9.188413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260901</td>\n",
       "      <td>37.257363</td>\n",
       "      <td>-7.200928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217987</td>\n",
       "      <td>37.965370</td>\n",
       "      <td>-7.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20120</td>\n",
       "      <td>39.499208</td>\n",
       "      <td>-7.171370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169450</td>\n",
       "      <td>42.033670</td>\n",
       "      <td>-7.933326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   poblacion_total        lat       lon\n",
       "0            14458  43.010088 -9.188413\n",
       "1           260901  37.257363 -7.200928\n",
       "2           217987  37.965370 -7.138822\n",
       "3            20120  39.499208 -7.171370\n",
       "4           169450  42.033670 -7.933326"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mallado.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a855dd",
   "metadata": {},
   "source": [
    "### Descarga y agregación diaria masiva de datos climáticos PVGIS (2019–2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ede27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de puntos: 27. Descargando 2019–2023...\n",
      "[1/27] lat=43.01008776, lon=-9.188413044333332 ... OK\n",
      "[2/27] lat=37.257363038571434, lon=-7.200928419999999 ... OK\n",
      "[3/27] lat=37.965370157307696, lon=-7.138822035 ... OK\n",
      "[4/27] lat=39.49920750818182, lon=-7.171370430363637 ... OK\n",
      "[5/27] lat=42.033670423414634, lon=-7.933325822585366 ... OK\n",
      "[6/27] lat=42.82670514307985, lon=-7.964607534338403 ... OK\n",
      "[7/27] lat=36.841508026165414, lon=-5.42390867006015 ... OK\n",
      "[8/27] lat=38.095268199430606, lon=-5.974638156576512 ... OK\n",
      "[9/27] lat=39.98708255200837, lon=-5.740223103259415 ... OK\n",
      "[10/27] lat=41.29388043232274, lon=-5.572345771344744 ... OK\n",
      "[11/27] lat=42.69003347615384, lon=-5.659510861418462 ... OK\n",
      "[12/27] lat=37.01394045681416, lon=-3.5120165887123895 ... OK\n",
      "[13/27] lat=38.03343402121848, lon=-3.4943284926764706 ... OK\n",
      "[14/27] lat=39.97014820842106, lon=-3.5742388449760765 ... OK\n",
      "[15/27] lat=41.327208103962704, lon=-3.6299377959358976 ... OK\n",
      "[16/27] lat=42.73470266318117, lon=-3.411960446252496 ... OK\n",
      "[17/27] lat=37.1895892648, lon=-2.15100941788 ... OK\n",
      "[18/27] lat=38.38605901333334, lon=-1.027689894575 ... OK\n",
      "[19/27] lat=39.71450716622951, lon=-1.081708218114754 ... OK\n",
      "[20/27] lat=41.328310791879936, lon=-1.4155092716097946 ... OK\n",
      "[21/27] lat=42.73848368829977, lon=-1.703265537751678 ... OK\n",
      "[22/27] lat=38.763722931282054, lon=-0.0363610714102564 ... OK\n",
      "[23/27] lat=40.04784122132075, lon=0.0191678991509433 ... OK\n",
      "[24/27] lat=41.4912567754952, lon=1.0076210190271566 ... OK\n",
      "[25/27] lat=42.39658406186567, lon=0.9725778692089552 ... OK\n",
      "[26/27] lat=41.833976415406504, lon=2.5303477847804876 ... OK\n",
      "[27/27] lat=42.27472393463917, lon=2.7892859614226806 ... OK\n",
      "\n",
      "✅ Guardado resultados UTC: pvgis_diario_2019_2023_utc_20260202_2210.csv (filas: 49302)\n",
      "✅ Guardado resultados Europe/Madrid: pvgis_diario_2019_2023_europe_madrid_20260202_2210.csv (filas: 49329)\n",
      "✅ No hubo errores.\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# PVGIS - Procesamiento masivo 2019-2023\n",
    "# Salida diaria en UTC y Europe/Madrid\n",
    "# ===========================================\n",
    "\n",
    "# ---------- Parámetros ----------\n",
    "INPUT_CSV = \"mallado.csv\"\n",
    "OUTPUT_OK_UTC = f'pvgis_diario_2019_2023_utc_{fecha}.csv'\n",
    "OUTPUT_OK_LOCAL = f'pvgis_diario_2019_2023_europe_madrid_{fecha}.csv'\n",
    "OUTPUT_ERR = f'pvgis_errores_2019_2023_{fecha}.csv'\n",
    "START_YEAR, END_YEAR = 2019, 2023\n",
    "LOCAL_TZ = \"Europe/Madrid\"\n",
    "SLEEP_BETWEEN_CALLS_SEC = 0.2  # pausa entre consulta con el servicio (límite ~30 req/s)\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "PVGIS_BASE = \"https://re.jrc.ec.europa.eu/api/v5_3/seriescalc\"\n",
    "\n",
    "def build_seriescalc_url(lat, lon, startyear=None, endyear=None, raddatabase=None, components=0, outputformat=\"json\"):\n",
    "    params = {\"lat\": lat, \"lon\": lon}\n",
    "    if startyear is not None:\n",
    "        params[\"startyear\"] = int(startyear)\n",
    "    if endyear is not None:\n",
    "        params[\"endyear\"] = int(endyear)\n",
    "    if raddatabase:\n",
    "        params[\"raddatabase\"] = raddatabase\n",
    "    params[\"components\"] = int(components)\n",
    "    params[\"outputformat\"] = outputformat\n",
    "    return f\"{PVGIS_BASE}?{urlencode(params)}\"\n",
    "\n",
    "def parse_time_mixed(s):\n",
    "    \"\"\"Acepta 'YYYY-MM-DDTHH:MM:SSZ' y 'YYYYMMDD:HHMM'.\"\"\"\n",
    "    s = str(s)\n",
    "    if re.fullmatch(r\"\\d{8}:\\d{4}\", s):\n",
    "        return pd.to_datetime(s, format=\"%Y%m%d:%H%M\", utc=True)\n",
    "    return pd.to_datetime(s, utc=True, errors=\"coerce\")\n",
    "\n",
    "def choose_radiation_column(df):\n",
    "    \"\"\"Prefiere G(i); si no existe, usa G(h). Devuelve el nombre de la columna o None.\"\"\"\n",
    "    if \"G(i)\" in df.columns:\n",
    "        return \"G(i)\"\n",
    "    if \"G(h)\" in df.columns:\n",
    "        return \"G(h)\"\n",
    "    return None\n",
    "\n",
    "def aggregate_daily(df, rad_col, tz=None):\n",
    "    \"\"\"\n",
    "    Agrega a diario. Si tz es None, trabaja en UTC (índice debe ser tz-aware UTC).\n",
    "    Si tz es string (p.ej. 'Europe/Madrid'), convierte con tz_convert antes de resamplear.\n",
    "    Devuelve DataFrame agregado (índice diario) sin lat/lon aún.\n",
    "    \"\"\"\n",
    "    if tz:\n",
    "        df_use = df.tz_convert(tz)\n",
    "    else:\n",
    "        df_use = df\n",
    "\n",
    "    # Diccionario de agregaciones\n",
    "    agg_dict = {}\n",
    "    if \"T2m\" in df_use.columns:\n",
    "        agg_dict.update({\n",
    "            \"T2m_min\": (\"T2m\", \"min\"),\n",
    "            \"T2m_max\": (\"T2m\", \"max\"),\n",
    "            \"T2m_mean\": (\"T2m\", \"mean\"),\n",
    "        })\n",
    "    if rad_col and rad_col in df_use.columns:\n",
    "        agg_dict[\"Rad_mean\"] = (rad_col, \"mean\")\n",
    "    if \"WS10m\" in df_use.columns:\n",
    "        agg_dict[\"WS10m_mean\"] = (\"WS10m\", \"mean\")\n",
    "\n",
    "    if not agg_dict:\n",
    "        # Nada que agregar\n",
    "        return None\n",
    "\n",
    "    daily = df_use.resample(\"D\").agg(**agg_dict)\n",
    "\n",
    "    # Renombrado y redondeo\n",
    "    rename_map = {\n",
    "        \"T2m_min\": \"Temp_min_C\",\n",
    "        \"T2m_max\": \"Temp_max_C\",\n",
    "        \"T2m_mean\": \"Temp_media_C\",\n",
    "        \"Rad_mean\": \"RadiacionGlobal_media_Wm2\",\n",
    "        \"WS10m_mean\": \"Viento_media_ms\",\n",
    "    }\n",
    "    daily = daily.rename(columns=rename_map).round({\n",
    "        \"Temp_min_C\": 2,\n",
    "        \"Temp_max_C\": 2,\n",
    "        \"Temp_media_C\": 2,\n",
    "        \"RadiacionGlobal_media_Wm2\": 1,\n",
    "        \"Viento_media_ms\": 2\n",
    "    })\n",
    "\n",
    "    return daily\n",
    "\n",
    "def process_point(lat, lon, start_year=START_YEAR, end_year=END_YEAR, timeout=60):\n",
    "    \"\"\"\n",
    "    Descarga serie horaria 2019-2023 para un punto y devuelve:\n",
    "      (daily_utc, daily_local, None) si OK,\n",
    "      (None, None, error_dict) si falla.\n",
    "    \"\"\"\n",
    "    url = build_seriescalc_url(lat, lon, startyear=start_year, endyear=end_year, components=0, outputformat=\"json\")\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout)\n",
    "    except requests.RequestException as e:\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": None, \"error\": f\"RequestException: {e}\"}\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        err_msg = None\n",
    "        try:\n",
    "            err_msg = r.json().get(\"message\")\n",
    "        except Exception:\n",
    "            err_msg = r.text[:500]\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": r.status_code, \"error\": err_msg}\n",
    "\n",
    "    try:\n",
    "        data = r.json()\n",
    "        hourly = data.get(\"outputs\", {}).get(\"hourly\", None)\n",
    "        if hourly is None or len(hourly) == 0:\n",
    "            return None, None, {\"lat\": lat, \"lon\": lon, \"status\": 200, \"error\": \"Sin 'outputs.hourly' o vacío\"}\n",
    "        df = pd.DataFrame(hourly)\n",
    "    except Exception as e:\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": 200, \"error\": f\"JSON/estructura inesperada: {e}\"}\n",
    "\n",
    "    # Parseo de fechas\n",
    "    if \"time\" not in df.columns:\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": 200, \"error\": \"Columna 'time' no encontrada\"}\n",
    "    df[\"time\"] = df[\"time\"].map(parse_time_mixed)\n",
    "    if df[\"time\"].isna().all():\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": 200, \"error\": \"No se pudo parsear ninguna fecha\"}\n",
    "\n",
    "    # Ordenar e indexar\n",
    "    df = df.sort_values(\"time\").set_index(\"time\")\n",
    "\n",
    "    # Asegurar formato numéricos\n",
    "    for col in [\"T2m\", \"WS10m\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    rad_col = choose_radiation_column(df)\n",
    "    if rad_col:\n",
    "        df[rad_col] = pd.to_numeric(df[rad_col], errors=\"coerce\")\n",
    "\n",
    "    # Verificación de columnas útiles\n",
    "    has_any = any(c in df.columns for c in [\"T2m\", \"WS10m\", rad_col] if c)\n",
    "    if not has_any:\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": 200, \"error\": \"No hay columnas útiles (T2m/WS10m/G(i)/G(h))\"}\n",
    "\n",
    "    # Agregación diaria en UTC y en hora local\n",
    "    daily_utc = aggregate_daily(df, rad_col, tz=None)     # --> UTC\n",
    "    daily_local = aggregate_daily(df, rad_col, tz=LOCAL_TZ) # --> Local\n",
    "\n",
    "    if daily_utc is None and daily_local is None:\n",
    "        return None, None, {\"lat\": lat, \"lon\": lon, \"status\": 200, \"error\": \"No se pudo construir agregación diaria\"}\n",
    "\n",
    "    # Añadir columnas de fecha y lat/lon\n",
    "    if daily_utc is not None:\n",
    "        daily_utc = daily_utc.copy()\n",
    "        daily_utc[\"date_utc\"] = daily_utc.index.tz_convert(\"UTC\").date\n",
    "        daily_utc = daily_utc.reset_index(drop=True)\n",
    "        daily_utc[\"lat\"] = lat\n",
    "        daily_utc[\"lon\"] = lon\n",
    "\n",
    "    if daily_local is not None:\n",
    "        daily_local = daily_local.copy()\n",
    "        daily_local[\"date_local\"] = daily_local.index.tz_convert(LOCAL_TZ).date\n",
    "        daily_local = daily_local.reset_index(drop=True)\n",
    "        daily_local[\"lat\"] = lat\n",
    "        daily_local[\"lon\"] = lon\n",
    "\n",
    "    return daily_utc, daily_local, None\n",
    "\n",
    "# ---------- Carga de coordenadas ----------\n",
    "if not os.path.exists(INPUT_CSV):\n",
    "    raise FileNotFoundError(f\"No se encuentra {INPUT_CSV} en el directorio actual: {os.getcwd()}\")\n",
    "\n",
    "coords = pd.read_csv(INPUT_CSV)\n",
    "if not {\"lat\", \"lon\"}.issubset(set(coords.columns)):\n",
    "    raise ValueError(f\"El fichero debe contener columnas 'lat' y 'lon'. Columnas leídas: {coords.columns.tolist()}\")\n",
    "\n",
    "# ---------- Bucle principal ----------\n",
    "all_utc = []\n",
    "all_local = []\n",
    "errors = []\n",
    "\n",
    "print(f\"Total de puntos: {len(coords)}. Descargando 2019–2023...\")\n",
    "\n",
    "for i, row in coords.iterrows():\n",
    "    lat, lon = float(row[\"lat\"]), float(row[\"lon\"])\n",
    "    print(f\"[{i+1}/{len(coords)}] lat={lat}, lon={lon} ...\", end=\" \")\n",
    "\n",
    "    daily_utc, daily_local, err = process_point(lat, lon)\n",
    "    if err is not None:\n",
    "        errors.append(err)\n",
    "        print(f\"ERROR -> {err.get('status')}: {err.get('error')}\")\n",
    "    else:\n",
    "        if daily_utc is not None:\n",
    "            all_utc.append(daily_utc)\n",
    "        if daily_local is not None:\n",
    "            all_local.append(daily_local)\n",
    "        print(\"OK\")\n",
    "    time.sleep(SLEEP_BETWEEN_CALLS_SEC)\n",
    "\n",
    "# ---------- Guardar salidas ----------\n",
    "def ensure_and_save(df_list, out_path, date_col_name):\n",
    "    if not df_list:\n",
    "        return 0\n",
    "    out = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Orden de columnas\n",
    "    cols_common = [\"lat\", \"lon\", date_col_name,\n",
    "                   \"Temp_min_C\", \"Temp_max_C\", \"Temp_media_C\",\n",
    "                   \"RadiacionGlobal_media_Wm2\", \"Viento_media_ms\"]\n",
    "    for c in cols_common:\n",
    "        if c not in out.columns:\n",
    "            out[c] = pd.NA\n",
    "    out = out[cols_common]\n",
    "    out.to_csv(out_path, index=False)\n",
    "    return len(out)\n",
    "\n",
    "n_utc = ensure_and_save(all_utc, OUTPUT_OK_UTC, \"date_utc\")\n",
    "n_local = ensure_and_save(all_local, OUTPUT_OK_LOCAL, \"date_local\")\n",
    "\n",
    "if n_utc:\n",
    "    print(f\"\\n✅ Guardado resultados UTC: {OUTPUT_OK_UTC} (filas: {n_utc})\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No se obtuvieron resultados UTC.\")\n",
    "\n",
    "if n_local:\n",
    "    print(f\"✅ Guardado resultados Europe/Madrid: {OUTPUT_OK_LOCAL} (filas: {n_local})\")\n",
    "else:\n",
    "    print(\"⚠️ No se obtuvieron resultados Europe/Madrid.\")\n",
    "\n",
    "if errors:\n",
    "    err_df = pd.DataFrame(errors)\n",
    "    err_df.to_csv(OUTPUT_ERR, index=False)\n",
    "    print(f\"⚠️ Guardado log de errores: {OUTPUT_ERR} (filas: {len(err_df)})\")\n",
    "else:\n",
    "    print(\"✅ No hubo errores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe1208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mi_entorno_Kschool)",
   "language": "python",
   "name": "mi_entorno_kschool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
